device: gpu
gpu_platform_id: 0
gpu_device_id: 0

task: train
objective: regression
metric: rmse
boosting_type: gbdt

# Agressif mais contrôlé
learning_rate: 0.01          # ton 0.005 + 8000 trees = trop lent/overfit
n_estimators: 5000           # 8000 avec des arbres monstrueux = overfit assuré

num_leaves: 768              # 2048 = suicide total ; 768 = agressif, viable
max_depth: -1
max_bin: 511                 # OK pour agressif, mais réglages cohérents nécessaires

# Sous-échantillonnage contrôlé
feature_fraction: 0.8        # 0.95 = trop proche de full → variance explosive
bagging_fraction: 0.7        # 0.90 = dangereux ; 0.7 = stabilité
bagging_freq: 1

# Anti-variance (indispensable)
min_data_in_leaf: 50         # tu avais 20 = variance infinie
min_sum_hessian_in_leaf: 0.1 # critique, sinon l'arbre split n'importe où

# Régularisation agressive mais nécessaire
lambda_l1: 0.0
lambda_l2: 10.0              # 1.0 est beaucoup trop faible pour un modèle large
min_gain_to_split: 0.0

two_round: True
boost_from_average: False
verbosity: -1
